{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0a3f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import openai\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "endpoint = \"\"\n",
    "api_key = \"\"\n",
    "model = \"gpt-4o-mini\"\n",
    "\n",
    "\n",
    "# Define the directory containing the markdown files\n",
    "directory = 'repo/data/markdown'\n",
    "\n",
    "# Define the maximum number of files to process\n",
    "max_files = 5000  # Change this value to the desired maximum number of files\n",
    "\n",
    "# Initialize a counter for processed files\n",
    "processed_files = 0\n",
    "\n",
    "# CSV file output\n",
    "output_csv = 'questions.csv'\n",
    "open('questions.csv', 'w').close()\n",
    "\n",
    "def process_question(content):\n",
    "    client = openai.AzureOpenAI(\n",
    "        azure_endpoint=endpoint,\n",
    "        api_key=api_key,\n",
    "        api_version=\"2024-08-01-preview\"\n",
    ")\n",
    "    message_text = [\n",
    "        {\"role\": \"system\", \"content\": \"Du bist ein AI Assistent zur Erstellung von Fragen zu Textabschnitten. Du erhälst als content den entsprechenden Text. Die Frage sollte so gestellt werden, dass das übergreifende Thema klar aus der Frage selbst hervorgeht.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Stelle genau eine Frage zum Inhalt dieses Textes:\" + content},\n",
    "    ]\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,  # Ensure the model name is correct\n",
    "        messages=message_text,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "def write_to_csv(question, chunk, output_csv):\n",
    "    with open(output_csv, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file, delimiter='\\t')\n",
    "        # Write header if the file is empty\n",
    "        chunk = chunk.replace('#', '') \n",
    "        if file.tell() == 0:\n",
    "            writer.writerow(['Question', 'Chunk'])\n",
    "        writer.writerow([question, chunk])\n",
    "\n",
    "# Iterate through each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.md'):  # Check if the file is a markdown file\n",
    "        if processed_files >= max_files:\n",
    "            break  # Stop processing if the maximum number of files is reached\n",
    "        \n",
    "        file_path = os.path.join(directory, filename)\n",
    "        \n",
    "        # Open and read the file\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        \n",
    "        # Split the content into chunks based on \"##\" headers\n",
    "        chunks = re.split(r'(?=## )', content)\n",
    "        \n",
    "        # Process each chunk\n",
    "        for chunk in tqdm(chunks):\n",
    "            question = process_question(chunk)\n",
    "           # print(question)\n",
    "           #  print('---')  # Separator between chunks\n",
    "            \n",
    "            # Write the chunk and question to the CSV file\n",
    "            write_to_csv(question, chunk, output_csv)\n",
    "        \n",
    "        # Increment the processed files counter\n",
    "        processed_files += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5206d22d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
